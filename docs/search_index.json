[["glm.html", "Capítulo 4 Modelos de Regresión Avanzados 4.1 Regresión No Lineal 4.2 Regresión Logística 4.3 Regresión Poisson", " Capítulo 4 Modelos de Regresión Avanzados Here is a review of existing methods. 4.1 Regresión No Lineal 4.1.1 Ejercicios 4.2 Regresión Logística 4.2.1 Ejercicios 4.3 Regresión Poisson 4.3.1 Introducción La Regresión Poisson es útil cuando se tiene una variable aleatoria respuesta \\(Y\\) que representa conteos por unidad de distancia, área, volúmen o tiempo, y es de interés predecir el número esperado de dichos conteos a partir de un conjunto de factores controlables independientes \\(X_1, X_2, \\ldots, X_k\\). La Regresión Poisson hace parte del Modelo Lineal Generalizado. Puesto que \\(Y\\) representa conteos independientes, es natural pensar que la distribución Poisson sea un plausible modelo para describir el proceso que genera dichos conteos. Por lo tanto, \\[ Y \\sim \\text{Poisson}(\\lambda), \\quad \\lambda &gt; 0, \\] donde \\(\\lambda\\) es el parámetro de la distribución Poisson. Además, \\(E[Y] = \\text{Var}[Y] = \\lambda\\). Como se discutirá más adelante, esta es una propiedad fundamental de la distribución Poisson que tiene implicaciones importantes en el modelo de Regresión Poisson. Con frecuencia, este parámetro se interpreta, por ejemplo, como (1) el número esperado de unidades defectuosas por hora; (2) el número esperado de defectos por metro cuadrado de baldosa producido; o (3) el número esperado de productos defectuosos por unidad de empaque. Formalmente, \\(\\lambda\\) puede verse como la tasa a la que ocurren los eventos de interés. La función de masa de probabilidad de \\(Y\\) está dada por: \\[ P(Y = y | \\lambda) = \\frac{e^{-\\lambda}\\lambda^y}{y!}, \\quad y=0,1,\\ldots \\] 4.3.2 Por qué? El modelo de Regresión Poisson aparece como una alternativa para incluir información de los factores controlables del proceso en la estimación del parámetro \\(\\lambda\\) , a través de un predictor lineal. Posteriormente, al tener condiciones definidas de operación, es decir, valores específicos para las variables independientes, podremos calcular \\(\\lambda\\) como \\[\\hat{\\lambda} = f(x_1, x_2, \\ldots, x_k).\\] Formalmente, esto es \\[ \\log\\left(\\lambda\\right) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots \\beta_kx_k + \\epsilon \\] donde \\(\\mathbf{\\beta} = (\\beta_0, \\beta_1, \\ldots, \\beta_k)\\) son los coeficientes del modelo y \\(\\epsilon\\) es el error aleatorio. A partir de esta expresión es fácil llegar a que \\[\\begin{equation} \\hat\\lambda = e^{\\hat{\\beta}_0 + \\hat{\\beta}_1x_1 + \\hat{\\beta}_2x_2 - \\cdots +\\hat{\\beta}_kx_k}\\cdot \\end{equation}\\] Así, \\[Y \\sim \\text{Poisson}(\\hat{\\lambda})\\] y \\[\\begin{align} P(Y = y | x_1, x_2, \\ldots, x_k) &amp;= P(Y|\\hat{\\lambda}) \\\\ &amp;= \\frac{e^{-\\hat{\\lambda}}\\hat{\\lambda}^y}{y!}\\cdot \\end{align}\\] Consideremos un proceso en el que se contabilizan el número de artículos defectuosos por cada unidad de empaque producida y supongamos que se controlan las variables \\(x_1\\) y \\(x_2\\). Si definimos \\[Y = \\text{Número de artículos defectuosos por unidad de empaque},\\] entonces \\(Y\\sim\\text{Poisson}(\\lambda)\\), \\(\\lambda&gt;0\\). A partir de una muestra de tamaño \\(n\\), es fácil llegar a que un estimador insesgado de \\(\\lambda\\) es \\[\\hat{\\lambda} = \\frac{1}{n}\\sum_{i=1}^n y_i.\\] Sin embargo, observe que al emplear este estimador de \\(\\lambda\\), no tenemos en cuenta información adicional sobre dicho parámetro que las variables \\(x_1\\) y \\(x_2\\) pudieran proporcionarnos. 4.3.3 Ejemplo Se tienen datos de un experimento en el que se empacaron 150 unidades de empaque de un producto particular. Cada unidad de empaque tiene 10 unidades de producto. Una vez empacadas, a cada empaque se le realizó inspección 100% y se registró el número de artículos defectuosos, además de las condiciones de operación de la máquina (variables \\(x_1\\) y \\(x_2\\)) y el tipo de máquina (variable \\(x_3\\)). # lectura de datos url &lt;- &quot;https://www.dropbox.com/s/xpxy928ugcxr3ck/machine.txt?dl=1&quot; d &lt;- read.table(url, header = TRUE) # primeras 4 filas de los datos head(d, 4) ## x1 x2 x3 y ## 1 -0.56047565 0.7877388 M2 0 ## 2 -0.23017749 0.7690422 M1 0 ## 3 1.55870831 0.3322026 M2 0 ## 4 0.07050839 -1.0083766 M2 0 La distribución del número de artículos defectuosos por unidad de empaque es: ## barplot require(ggplot2) # Freq &lt;- with(d, table(y)) ggplot(d, aes(x = as.factor(y))) + geom_bar(fill = &quot;midnightblue&quot;) + xlab(&quot;Número de artículos defectuosos&quot;) + ylab(&quot;Frecuencia&quot;) + theme_minimal() Figura 4.1: Número de artículos defectuosos por unidad de empaque en la muestra. Puesto que trabajamos con conteos, una distribución de probabilidad posible que describe la variable \\(Y\\) es \\(Y\\sim \\text{Poisson}(\\lambda)\\), \\(\\lambda&gt;0\\). A partir de la muestra, se obtiene que \\[\\hat\\lambda = \\frac{1}{150}\\sum_{i=1}^{150}y_i = 0.9\\] Sin embargo, observe que la estimación de \\(\\lambda\\) no tienen en cuenta las coordenadas \\((x_1, x_2)\\) ni de la máquina en la que se empaca el producto, lo cual sería deseable. 4.3.4 Modelo ajustado Puesto que las condiciones de operación y la máquina en la que se empaca el producto podrían ser determinantes en el número de artículos defectuosos por unidad de empaque que se obtienen, planteamos un modelo de Regresión Poisson. El modelo ajustado es: ## modelo de Regresión Poisson ## la funcion clave es glm --- para ayuda ver ?glm ## como la respuesta es binaria, debemos seleccionar family = poisson() fit &lt;- glm(y ~ ., data = d, family = poisson()) # coeficientes estimados summary(fit) ## ## Call: ## glm(formula = y ~ ., family = poisson(), data = d) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.4277 -0.7602 -0.3576 0.2688 2.1429 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.6283 0.1542 -4.074 4.62e-05 *** ## x1 0.9460 0.1037 9.125 &lt; 2e-16 *** ## x2 -1.3260 0.1425 -9.304 &lt; 2e-16 *** ## x3M2 -0.8869 0.1962 -4.521 6.15e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for poisson family taken to be 1) ## ## Null deviance: 348.68 on 149 degrees of freedom ## Residual deviance: 118.44 on 146 degrees of freedom ## AIC: 269.45 ## ## Number of Fisher Scoring iterations: 5 Para determinar si el modelo ajustado es mejor que el modelo y ~ 1, usamos una prueba de razón de verosimilitud (LRT en inglés). Aunque esta prueba esta implementada en el paquete base de R a través de la función anova, el reporte de los resultados es más informativo cuando usamos la función lrtest del paquete lmtest: ## verificar disponibilidad de lmtest if (!require(lmtest)) install.packages(&quot;lmtest&quot;) require(lmtest) ## comparación del modelos usando la LRT ajustamos un modelo simple nullmodel &lt;- glm(y ~ 1, data = d, family = poisson()) ## LRT lrtest(nullmodel, fit) ## Likelihood ratio test ## ## Model 1: y ~ 1 ## Model 2: y ~ x1 + x2 + x3 ## #Df LogLik Df Chisq Pr(&gt;Chisq) ## 1 1 -245.84 ## 2 4 -130.73 3 230.24 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Conclusión. El modelo de Regresión Poisson que incluye las covariables \\(x_1, x_2\\) y \\(x_3\\) es significativamente mejor que un modelo sin ellas para explicar el número de artículos defectuosos por unidad de empaque. Una forma de determinar que el modelo tiene buen ajuste, es a través de la utilización del Deviance. Para más detalles, ver la sección 4.4.9 del texto Beyond Multiple Linear Regression. La idea fundamental es consiste calcular el valor \\(p\\) de la prueba de hipótesis \\[ \\begin{align} H_0&amp;: \\text{El modelo propuesto tiene bien ajuste.} \\\\ H_1&amp;: \\text{El modelo propuesto NO tiene bien ajuste.} \\end{align} \\] En este caso, el valor \\(p\\) de la prueba de hipótesis puede cacularse fácilmente como: ## deviance test with(fit, 1-pchisq(deviance, df.residual)) ## [1] 0.9542188 Como el valor \\(p\\) es \\(&gt;0.05\\), decimos que el modelo no sufre de falta de ajuste. En otras palabras, que nuestro modelo ajusta bien los datos. Sobredispersión El modelo de Regresión Poisson puede sufrir de sobredispersión. Este concepto se refiere a que, en la distribución Poisson, \\(\\text{Var}[Y] &gt; E[Y]\\), es decir, que el supuesto principal de la distribución no se cumple. En nuestro caso, Una posible solución a la violación de la propiedad fundamental de la distribución Poisson es ajustar un modelo de Regresión Poisson con función de enlace tipo quasipoisson y estimar el parámetro de sobredispersión \\(\\phi\\) haciendo: ## ajuste del modelo con enlace quasipoisson fitq &lt;- glm(y ~ ., data = d, family = quasipoisson) ## ahora estimamos la dispersión summary(fitq) ## ## Call: ## glm(formula = y ~ ., family = quasipoisson, data = d) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.4277 -0.7602 -0.3576 0.2688 2.1429 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.6283 0.1505 -4.173 5.13e-05 *** ## x1 0.9460 0.1012 9.348 &lt; 2e-16 *** ## x2 -1.3260 0.1391 -9.531 &lt; 2e-16 *** ## x3M2 -0.8869 0.1915 -4.631 7.97e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for quasipoisson family taken to be 0.9529908) ## ## Null deviance: 348.68 on 149 degrees of freedom ## Residual deviance: 118.44 on 146 degrees of freedom ## AIC: NA ## ## Number of Fisher Scoring iterations: 5 A partir de estos rresultados, se llega a que \\(\\hat{\\phi} = 0.953\\), lo cual indica que los datos no están sobredispersos. Para estar completamente seguros, podemos hacer una prueba formal del tipo \\[ \\begin{align} H_0: \\phi = 1 \\\\ H_1: \\phi &gt; 1 \\end{align} \\] En R, esta prueba está implementada en la función dispersiontest del paquete AER: ## disponibilidad del paquete AER if(!require(AER)) install.packages(&#39;AER&#39;) require(AER) ## prueba para el coeficiente de dispersión dispersiontest(fit, trafo = 1) ## ## Overdispersion test ## ## data: fit ## z = -0.90813, p-value = 0.8181 ## alternative hypothesis: true alpha is greater than 0 ## sample estimates: ## alpha ## -0.07419873 Conclusión: No hay evidencia de sobredispersión. Cuando hay sobredispersión, una alternativa al modelo de Regresión Poisson es una Regresión Binomial Negativa. Este modelo puede ajustarse en R con la función `glm.nb del paquete MASS. Exceso de ceros Los datos provenientes de procesos de conteo podrían sufrir de exceso de ceros. Esto se refiere, fuundamentalmente, a que el número de ceros en los datos es mayor al que esperaríamos si estos siguieran, en realidad, una distribución Poisson. Por ejemplo, si \\(Y\\sim \\text{Poisson}(\\lambda)\\) y tuviéramos una muestra de tamaño \\(n\\), el número esperado de ceros sería \\[n_0 = n\\,P(Y=0|\\lambda) = n\\,e^{-\\lambda}\\] Si en la muestra de tamaño \\(n\\) observamos que el número de ceros es \\(n^\\prime&gt;&gt;&gt;n_0\\), entonces los datos están inflados con ceros. Por lo tanto, un modelo del tipo Zero-inflated Poisson Regression sería más apropiado. En nuestro caso, el número de ceros en la muestra es ## número de ceros with(d, sum(y == 0)) ## [1] 93 Bajo el modelo Poisson, se esperan ## número esperado de ceros mean(d$y)*NROW(d) ## [1] 135 por lo que no existe un exceso de estos. 4.3.5 Cálculo e inferencia para \\(\\hat{\\lambda}\\) Recordemos \\(\\hat{\\lambda}\\) es el número esperado de artículos defectuosos por unidad de empaque cuando se conocen las variables \\(x_1,x_2\\) y \\(x_3\\). En otras palabras, \\(\\hat{\\lambda} = f(x_1, x_2, x_3)\\). A partir del modelo ajustado, la tasa de artículos defectuosos por unidad de empaque puede obtenerse como: ## cálculo de lambdahat lambdahat &lt;- predict(fit, type = &quot;response&quot;) ## ahora incluyamos lambdahat para los 5 primeros individuos d &lt;- data.frame(id = 1:NROW(d), d, lambdahat) head(d, 5) ## id x1 x2 x3 y lambdahat ## 1 1 -0.56047565 0.7877388 M2 0 0.04550495 ## 2 2 -0.23017749 0.7690422 M1 0 0.15478211 ## 3 3 1.55870831 0.3322026 M2 0 0.61806211 ## 4 4 0.07050839 -1.0083766 M2 0 0.89455575 ## 5 5 0.12928774 -0.1194526 M2 0 0.29097707 Si las condiciones fueran \\((2, -1)\\) y \\((-2, 4)\\), y se usara la máquina es M1, la tasa de artículos defectuosos por unidad de empaque sería: # que pasa para las coordenadas (2, -1), (-2, 4) y máquina M1? predict(fit, newdata = data.frame(x1 = c(2, -2), x2 = c(-1, 4), x3 = &#39;M1&#39;), type = &#39;response&#39;, se.fit = TRUE) ## $fit ## 1 2 ## 1.332580e+01 3.999625e-04 ## ## $se.fit ## 1 2 ## 2.7092492536 0.0002847542 ## ## $residual.scale ## [1] 1 Un intervalo de confianza del 95% para \\(\\lambda\\) cuando \\(x_1=2\\), \\(x_2=-1\\), y \\(x3=\\text{M1}\\) está dado por \\[ 13.325 \\pm 1.96\\times2.709 = (8.015, 18.635) \\] Esto indica que si trabajamos con estas condiciones de operación, se espera que el número de artículos defectuosos por unidad de empaque en la población esté en el intervalo \\((8.015, 18.635)\\) con una confianza del 95%. 4.3.6 Estimación del número de errores Para las condiciones \\((2,-1)\\) se esperan obtener \\(\\hat\\lambda = 13.325\\) artículos defectuosos por unidad de empaque. Utilizando simulación, es fácil determinar la distribución del número de artículos defectuosos que se obtendrían en 1000 unidades de empaque producidas bajo estas condiciones. A partir de estos resultados podemos entonces calcular un intervalo de confianza del 95% para \\(Y_0\\), no para \\(\\lambda\\). ## número de errores en 10 intentos para 1000 hombres ## cuando el punto se proyecta en (2, -1) lambdahat &lt;- predict(fit, newdata = data.frame(x1 = 2, x2 = -1, x3 = &#39;M1&#39;), type = &#39;response&#39;) ## semilla aleatoria set.seed(123) ## número de unidades de empaque N &lt;- 1000 ## número de errores yhat &lt;- rpois(N, lambdahat) ## intervalo de confianza del 95% (ci &lt;- quantile(yhat, probs = c(0.025, 0.975))) ## 2.5% 97.5% ## 7 21 Esto indica que, bajo estas condiciones, el número de artículos defectuosos esperado para la próxima unidad de empaque estará entre 7 y 21, con una confianza del 95%. Gráficamente tendríamos: ## barplot para el número de errores en (2, -1, &#39;M1&#39;) pred &lt;- data.frame(yhat) ggplot(pred, aes(x = yhat)) + geom_bar(fill = &quot;midnightblue&quot;) + xlab(&quot;Número de artículos defectuosos para (2, -1, &#39;M1&#39;)&quot;) + ylab(&quot;Frecuencia&quot;) + geom_vline(xintercept = ci, color = &quot;green&quot;) + geom_vline(xintercept = lambdahat, color = &quot;red&quot;) + theme_minimal() Figura 4.2: Número predicho de artículos defectuosos por unidad de empaque. 4.3.7 Cálculo de probabilidades A partir del modelo ajustado es posible calcular probabilidades teniendo en cuenta las coordenadas \\((x_1, x_2)\\) y el sexo o variable \\(x_3\\). Por ejemplo la probabilidad de que una persona cometa exactamente 3 errores en función de \\((x_1, x_2, x_3)\\) puede expresarse como: \\[P(Y = 3 | x_1, x_2, x_3) = \\frac{e^{-\\hat\\lambda}{\\hat\\lambda}^3}{3!}\\] donde \\[\\hat\\lambda = e^{-0.628 + 0.946x_1 - 1.326x_2 -0.887x_{3,\\text{M2}}}\\] con \\(x_{3,\\text{M2}}\\) una variable indicadora. Para el perfil \\((2, -1, \\texttt{M1})\\) se tiene que \\(\\hat\\lambda = 13.325\\). Así, \\[P(Y = 3 | 2, -1, \\texttt{M1}) = \\frac{e^{-13.325}{13.325}^3}{3!} \\approx 0.\\] 4.3.8 Variaciones El modelo de Regresión Poisson tiene algunas variaciones. Para mayor información, se sugiere consultar el paquete pscl (Jackman 2020) y el documento Regression Models for Count Data in R (Zeileis, Kleiber, and Jackman 2008). Referencias "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
